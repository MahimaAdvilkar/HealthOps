{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a81d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashut\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import importlib\n",
    "if 'src.services.faiss_service' in sys.modules:\n",
    "    importlib.reload(sys.modules['src.services.faiss_service'])\n",
    "if 'src.utils.document_chunker' in sys.modules:\n",
    "    importlib.reload(sys.modules['src.utils.document_chunker'])\n",
    "\n",
    "from src.services.faiss_service import FAISSService\n",
    "from src.utils.document_chunker import DocumentChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f0fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing services...\n",
      "\n",
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashut\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashut\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new FAISS index with dimension 384\n",
      "Initialized empty metadata store\n",
      "\n",
      "✓ Services initialized\n",
      "Chunk size: 1200 chars\n",
      "Chunk overlap: 200 chars\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing services...\\n\")\n",
    "faiss_service = FAISSService()\n",
    "chunker = DocumentChunker()\n",
    "print(f\"\\n✓ Services initialized\")\n",
    "print(f\"Chunk size: {chunker.chunk_size} chars\")\n",
    "print(f\"Chunk overlap: {chunker.chunk_overlap} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca78b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FAISS INDEX STATISTICS (BEFORE)\n",
      "============================================================\n",
      "Total Documents: 0\n",
      "Index Dimension: 384\n",
      "Embedding Model: all-MiniLM-L6-v2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "stats = faiss_service.get_stats()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FAISS INDEX STATISTICS (BEFORE)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Documents: {stats['total_documents']}\")\n",
    "print(f\"Index Dimension: {stats['index_dimension']}\")\n",
    "print(f\"Embedding Model: {stats['embedding_model']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7555f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading guidance documents from: c:\\projects\\HealthOps\\backend\\notebooks\\..\\data\\compliance\\guidance\n",
      "\n",
      "Found 2 guidance document(s):\n",
      "  - GDPR_Healthcare.txt\n",
      "  - HIPAA_Guidelines.txt\n"
     ]
    }
   ],
   "source": [
    "guidance_dir = Path(\"../data/compliance/guidance\")\n",
    "\n",
    "print(\"Loading guidance documents from:\", guidance_dir.absolute())\n",
    "print()\n",
    "\n",
    "if not guidance_dir.exists():\n",
    "    print(\"✗ Guidance directory not found\")\n",
    "else:\n",
    "    files = list(guidance_dir.glob(\"*.txt\"))\n",
    "    print(f\"Found {len(files)} guidance document(s):\")\n",
    "    for f in files:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b2c247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DOCUMENT CHUNKING RESULTS\n",
      "============================================================\n",
      "\n",
      "Document: GDPR_Healthcare\n",
      "  Total Chunks: 55\n",
      "  Sections: 55\n",
      "  Avg Chunk Size: 118 chars\n",
      "  Min/Max: 0/276 chars\n",
      "  Total Characters: 6478\n",
      "\n",
      "Document: HIPAA_Guidelines\n",
      "  Total Chunks: 32\n",
      "  Sections: 32\n",
      "  Avg Chunk Size: 181 chars\n",
      "  Min/Max: 0/462 chars\n",
      "  Total Characters: 5780\n",
      "\n",
      "============================================================\n",
      "Total chunks across all documents: 87\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "all_chunks_data = chunker.chunk_directory(str(guidance_dir), \"*.txt\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOCUMENT CHUNKING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_chunks = 0\n",
    "for doc_id, chunks in all_chunks_data.items():\n",
    "    stats = chunker.get_chunk_stats(chunks)\n",
    "    total_chunks += stats['total_chunks']\n",
    "    \n",
    "    print(f\"\\nDocument: {doc_id}\")\n",
    "    print(f\"  Total Chunks: {stats['total_chunks']}\")\n",
    "    print(f\"  Sections: {stats['sections']}\")\n",
    "    print(f\"  Avg Chunk Size: {stats['avg_chunk_size']:.0f} chars\")\n",
    "    print(f\"  Min/Max: {stats['min_chunk_size']}/{stats['max_chunk_size']} chars\")\n",
    "    print(f\"  Total Characters: {stats['total_chars']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"Total chunks across all documents: {total_chunks}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff47f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample chunks from first document:\n",
      "\n",
      "Document: GDPR_Healthcare\n",
      "Showing first 3 chunks:\n",
      "\n",
      "Chunk 1:\n",
      "  ID: GDPR_Healthcare_sec0\n",
      "  Section: # GDPR Healthcare Compliance Guide\n",
      "  Type: section\n",
      "  Size: 0 chars\n",
      "  Text: ...\n",
      "\n",
      "Chunk 2:\n",
      "  ID: GDPR_Healthcare_sec1\n",
      "  Section: ## 1. Introduction to GDPR in Healthcare\n",
      "  Type: section\n",
      "  Size: 247 chars\n",
      "  Text: The General Data Protection Regulation (GDPR) sets strict requirements for how healthcare organizations process personal data of EU citizens. Healthcare data is considered a special category of person...\n",
      "\n",
      "Chunk 3:\n",
      "  ID: GDPR_Healthcare_sec2\n",
      "  Section: ## 2. Key Principles\n",
      "  Type: section\n",
      "  Size: 0 chars\n",
      "  Text: ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample chunks from first document:\\n\")\n",
    "\n",
    "first_doc = list(all_chunks_data.keys())[0]\n",
    "chunks = all_chunks_data[first_doc]\n",
    "\n",
    "print(f\"Document: {first_doc}\")\n",
    "print(f\"Showing first 3 chunks:\\n\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3], 1):\n",
    "    print(f\"Chunk {i}:\")\n",
    "    print(f\"  ID: {chunk['chunk_id']}\")\n",
    "    print(f\"  Section: {chunk['section_title']}\")\n",
    "    print(f\"  Type: {chunk['chunk_type']}\")\n",
    "    print(f\"  Size: {chunk['char_count']} chars\")\n",
    "    print(f\"  Text: {chunk['text'][:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b278c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding all chunks to FAISS index...\n",
      "\n",
      "Saved FAISS index and metadata\n",
      "============================================================\n",
      "FAISS INDEXING RESULTS\n",
      "============================================================\n",
      "Status: SUCCESS\n",
      "Message: Added 87 documents successfully\n",
      "Documents Added: 87\n",
      "Total Documents: 87\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding all chunks to FAISS index...\\n\")\n",
    "\n",
    "documents_to_add = []\n",
    "\n",
    "for doc_id, chunks in all_chunks_data.items():\n",
    "    for chunk in chunks:\n",
    "        documents_to_add.append({\n",
    "            \"id\": chunk['chunk_id'],\n",
    "            \"text\": chunk['text'],\n",
    "            \"document_type\": \"compliance_guidance\",\n",
    "            \"metadata\": {\n",
    "                \"source_document\": doc_id,\n",
    "                \"source_file\": chunk['source_file'],\n",
    "                \"section_title\": chunk['section_title'],\n",
    "                \"section_index\": chunk['section_index'],\n",
    "                \"chunk_index\": chunk['chunk_index'],\n",
    "                \"chunk_type\": chunk['chunk_type'],\n",
    "                \"char_count\": chunk['char_count']\n",
    "            }\n",
    "        })\n",
    "\n",
    "result = faiss_service.add_documents_batch(documents_to_add)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FAISS INDEXING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Status: {'SUCCESS' if result['success'] else 'FAILED'}\")\n",
    "print(f\"Message: {result['message']}\")\n",
    "if result['success']:\n",
    "    print(f\"Documents Added: {result['documents_added']}\")\n",
    "    print(f\"Total Documents: {result['total_documents']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8900c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: What are the requirements for protecting patient health information?\n",
      "============================================================\n",
      "\n",
      "Found 3 relevant chunks:\n",
      "\n",
      "1. Chunk ID: HIPAA_Guidelines_sec8\n",
      "   Similarity: 0.6227\n",
      "   Source: HIPAA_Guidelines\n",
      "   Section: ### 3.3 Individual Rights\n",
      "   Text: Patients have the right to:\n",
      "- Access their health information\n",
      "- Request amendments to their health information\n",
      "- Receive an accounting of disclosures\n",
      "- Request restrictions on certain uses and disclos...\n",
      "\n",
      "2. Chunk ID: GDPR_Healthcare_sec3\n",
      "   Similarity: 0.6099\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 2.1 Lawfulness, Fairness, and Transparency\n",
      "   Text: Healthcare organizations must process personal data lawfully, fairly, and in a transparent manner. Patients must be informed about how their data is being used....\n",
      "\n",
      "3. Chunk ID: HIPAA_Guidelines_sec3\n",
      "   Similarity: 0.5724\n",
      "   Source: HIPAA_Guidelines\n",
      "   Section: ### 2.1 Definition\n",
      "   Text: Protected Health Information (PHI) is any information about health status, provision of healthcare, or payment for healthcare that can be linked to an individual. This includes demographic information...\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY: How should we handle data breaches?\n",
      "============================================================\n",
      "\n",
      "Found 3 relevant chunks:\n",
      "\n",
      "1. Chunk ID: GDPR_Healthcare_sec31\n",
      "   Similarity: 0.5692\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 8.3 Breach Documentation\n",
      "   Text: All personal data breaches must be documented, including facts, effects, and remedial actions taken....\n",
      "\n",
      "2. Chunk ID: GDPR_Healthcare_sec29\n",
      "   Similarity: 0.5319\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 8.1 Notification to Supervisory Authority\n",
      "   Text: Personal data breaches must be reported to the relevant supervisory authority within 72 hours of becoming aware of the breach, unless the breach is unlikely to result in a risk to individuals' rights ...\n",
      "\n",
      "3. Chunk ID: GDPR_Healthcare_sec52\n",
      "   Similarity: 0.4953\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 14.3 Incident Response\n",
      "   Text: Maintain and test incident response procedures to ensure quick and effective response to breaches....\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY: What encryption is required for health records?\n",
      "============================================================\n",
      "\n",
      "Found 3 relevant chunks:\n",
      "\n",
      "1. Chunk ID: HIPAA_Guidelines_sec8\n",
      "   Similarity: 0.5480\n",
      "   Source: HIPAA_Guidelines\n",
      "   Section: ### 3.3 Individual Rights\n",
      "   Text: Patients have the right to:\n",
      "- Access their health information\n",
      "- Request amendments to their health information\n",
      "- Receive an accounting of disclosures\n",
      "- Request restrictions on certain uses and disclos...\n",
      "\n",
      "2. Chunk ID: GDPR_Healthcare_sec3\n",
      "   Similarity: 0.5451\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 2.1 Lawfulness, Fairness, and Transparency\n",
      "   Text: Healthcare organizations must process personal data lawfully, fairly, and in a transparent manner. Patients must be informed about how their data is being used....\n",
      "\n",
      "3. Chunk ID: GDPR_Healthcare_sec13\n",
      "   Similarity: 0.5414\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 4.1 Right to Access\n",
      "   Text: Patients have the right to obtain confirmation of whether their personal data is being processed and access to that data....\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY: What are GDPR patient rights?\n",
      "============================================================\n",
      "\n",
      "Found 3 relevant chunks:\n",
      "\n",
      "1. Chunk ID: HIPAA_Guidelines_sec8\n",
      "   Similarity: 0.5819\n",
      "   Source: HIPAA_Guidelines\n",
      "   Section: ### 3.3 Individual Rights\n",
      "   Text: Patients have the right to:\n",
      "- Access their health information\n",
      "- Request amendments to their health information\n",
      "- Receive an accounting of disclosures\n",
      "- Request restrictions on certain uses and disclos...\n",
      "\n",
      "2. Chunk ID: GDPR_Healthcare_sec13\n",
      "   Similarity: 0.5789\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ### 4.1 Right to Access\n",
      "   Text: Patients have the right to obtain confirmation of whether their personal data is being processed and access to that data....\n",
      "\n",
      "3. Chunk ID: GDPR_Healthcare_sec1\n",
      "   Similarity: 0.5668\n",
      "   Source: GDPR_Healthcare\n",
      "   Section: ## 1. Introduction to GDPR in Healthcare\n",
      "   Text: The General Data Protection Regulation (GDPR) sets strict requirements for how healthcare organizations process personal data of EU citizens. Healthcare data is considered a special category of person...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the requirements for protecting patient health information?\",\n",
    "    \"How should we handle data breaches?\",\n",
    "    \"What encryption is required for health records?\",\n",
    "    \"What are GDPR patient rights?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    result = faiss_service.search(query, top_k=3, document_type=\"compliance_guidance\")\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"\\nFound {len(result['results'])} relevant chunks:\\n\")\n",
    "        \n",
    "        for idx, doc in enumerate(result['results'], 1):\n",
    "            print(f\"{idx}. Chunk ID: {doc['document_id']}\")\n",
    "            print(f\"   Similarity: {doc['similarity_score']:.4f}\")\n",
    "            print(f\"   Source: {doc['metadata'].get('source_document', 'N/A')}\")\n",
    "            print(f\"   Section: {doc['metadata'].get('section_title', 'N/A')}\")\n",
    "            print(f\"   Text: {doc['text'][:200]}...\")\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"Search failed: {result['message']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ddd560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL STATISTICS\n",
      "============================================================\n",
      "Total Chunks Indexed: 87\n",
      "Embedding Model: all-MiniLM-L6-v2\n",
      "Vector Dimension: 384\n",
      "\n",
      "Document Types:\n",
      "  - compliance_guidance: 87\n",
      "\n",
      "Index Location: data\\compliance\\faiss_index\n",
      "============================================================\n",
      "\n",
      "✓ Guidance documents chunked and indexed successfully!\n",
      "✓ Ready for semantic search across all compliance sections!\n"
     ]
    }
   ],
   "source": [
    "final_stats = faiss_service.get_stats()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Chunks Indexed: {final_stats['total_documents']}\")\n",
    "print(f\"Embedding Model: {final_stats['embedding_model']}\")\n",
    "print(f\"Vector Dimension: {final_stats['index_dimension']}\")\n",
    "print(f\"\\nDocument Types:\")\n",
    "for doc_type, count in final_stats['document_types'].items():\n",
    "    print(f\"  - {doc_type}: {count}\")\n",
    "print(f\"\\nIndex Location: {final_stats['index_path']}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n✓ Guidance documents chunked and indexed successfully!\")\n",
    "print(\"✓ Ready for semantic search across all compliance sections!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
